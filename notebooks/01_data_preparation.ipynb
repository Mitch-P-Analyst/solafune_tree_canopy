{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "O-uFJyQRsTvr",
      "metadata": {
        "id": "O-uFJyQRsTvr"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3d28d1bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Packages\n",
        "import json\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "03b1b9d1",
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "NB_DIR = Path.cwd()\n",
        "REPO_ROOT = NB_DIR.parent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XwHQNY67uM59",
      "metadata": {
        "id": "XwHQNY67uM59"
      },
      "source": [
        "\n",
        "## JSON Conversion\n",
        "\n",
        "### Solafune JSON format to COCO format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1f69796c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved COCO annotations to: /Users/mitchellpalmer/Projects/solafune-canopy-capstone-clean/data/processed/JSONs/train_annotations_coco.json\n"
          ]
        }
      ],
      "source": [
        "# input and output paths\n",
        "input_path = REPO_ROOT / 'data/raw/JSONs/train_annotations.json'\n",
        "output_path = REPO_ROOT / 'data/processed/JSONs/train_annotations_coco.json'\n",
        "\n",
        "# read train annotations data\n",
        "with open(input_path) as f:\n",
        "    train_annotations = json.load(f)\n",
        "\n",
        "# initialize COCO data structure\n",
        "coco_data = {\n",
        "    \"images\": [],\n",
        "    \"annotations\": [],\n",
        "    \"categories\": [\n",
        "        {\"id\": 1, \"name\": \"individual_tree\", \"supercategory\": \"tree\"},\n",
        "        {\"id\": 2, \"name\": \"group_of_trees\", \"supercategory\": \"tree\"},\n",
        "    ]\n",
        "}\n",
        "\n",
        "# category mapping\n",
        "category_map = {\n",
        "    \"individual_tree\": 1,\n",
        "    \"group_of_trees\": 2\n",
        "}\n",
        "\n",
        "# initialize annotation and image ID counters\n",
        "annotation_id = 1\n",
        "image_id = 1\n",
        "\n",
        "# for each image...\n",
        "for image in train_annotations[\"images\"]:\n",
        "    \n",
        "    # add image metadata\n",
        "    coco_data[\"images\"].append(\n",
        "        {\n",
        "            \"id\": image_id,\n",
        "            \"file_name\": image[\"file_name\"],\n",
        "            \"width\": image[\"width\"],\n",
        "            \"height\": image[\"height\"]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # for each annotation in this image\n",
        "    for ann in image.get(\"annotations\", []):\n",
        "        # extract segmentation polygon\n",
        "        segmentation = ann[\"segmentation\"]\n",
        "\n",
        "        # skip if fewer than 3 points (expected to cause errors later)\n",
        "        if len(segmentation) < 6:\n",
        "            continue\n",
        "\n",
        "        # append annotation\n",
        "        coco_data[\"annotations\"].append(\n",
        "            {\n",
        "                \"id\": annotation_id,                                    # annotation ID\n",
        "                \"image_id\": image_id,                                   # image ID\n",
        "                \"category_id\": category_map[ann[\"class\"]],              # category ID\n",
        "                \"segmentation\": [segmentation],                         # segmentation polygon\n",
        "                \"area\": 0,                                              # area (not used but setting anyway)\n",
        "                \"bbox\": [                                               # bounding box\n",
        "                    min(segmentation[::2]),                             # ... x\n",
        "                    min(segmentation[1::2]),                            # ... y\n",
        "                    max(segmentation[::2]) - min(segmentation[::2]),    # ... w\n",
        "                    max(segmentation[1::2]) - min(segmentation[1::2])   # ... h\n",
        "                ],\n",
        "                \"iscrowd\": 0,                                           # is-crowded (not used but setting anyway)\n",
        "                \"score\": ann.get(\"confidence_score\", 1.0)               # confidence score (nonsense for ground-truth but setting anyway)\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # increment annotation ID counter\n",
        "        annotation_id += 1\n",
        "\n",
        "    # increment image ID counter\n",
        "    image_id += 1\n",
        "\n",
        "# ensure parent directory exists\n",
        "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# save output\n",
        "with open(output_path, \"w\") as f:\n",
        "    json.dump(coco_data, f, indent=2)\n",
        "\n",
        "print(f\"✅ Saved COCO annotations to: {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f948cd16",
      "metadata": {},
      "source": [
        "### COCO Format to YOLO Machine Learning Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1365d4c",
      "metadata": {
        "id": "a1365d4c",
        "outputId": "5e75d582-0692-496c-b6ae-69db3bd67318"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Annotations /Users/mitchellpalmer/Projects/solafune-canopy-capstone-clean/data/processed/JSONs/test_annotations_coco.json: 100%|██████████| 23/23 [00:00<00:00, 224.47it/s]\n",
            "Annotations /Users/mitchellpalmer/Projects/solafune-canopy-capstone-clean/data/processed/JSONs/train_annotations_coco.json: 100%|██████████| 150/150 [00:00<00:00, 269.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COCO data converted successfully.\n",
            "Results saved to /Users/mitchellpalmer/Projects/solafune-canopy-capstone-clean/data/temp_labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from ultralytics.data.converter import convert_coco\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Convert COCO annotations for instance segmentation\n",
        "from ultralytics.data.converter import convert_coco\n",
        "convert_coco (\n",
        "    labels_dir=REPO_ROOT/'data/processed/JSONs', # Target is the COCO converted JSON file in 'Data' directory\n",
        "    save_dir=REPO_ROOT/'data/temp_jsons', # Output is a YOLO compatible JSON  # Folder must not exist prior\n",
        "    use_keypoints= False,\n",
        "    use_segments=True\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f63fb0db",
      "metadata": {},
      "source": [
        "## Extract Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1008e8b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "def unzip_to_folder(zip_path, extract_to):\n",
        "    \"\"\"\n",
        "    Unzips a ZIP archive into a specified directory.\n",
        "    \"\"\"\n",
        "    extract_to = Path(extract_to)\n",
        "    extract_to.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "    macosx_folder = extract_to / '__MACOSX'\n",
        "    if macosx_folder.exists():\n",
        "        shutil.rmtree(macosx_folder)\n",
        "        \n",
        "    print(f\"✅ Unzipped: {zip_path} → {extract_to}\")\n",
        "\n",
        "def move_images(source_dir, dest_dir, image_extensions={'.jpg', '.jpeg', '.png', '.tif', '.tiff'}):\n",
        "    \"\"\"\n",
        "    Moves image files from source_dir to dest_dir (non-recursive).\n",
        "    \"\"\"\n",
        "    source_dir = Path(source_dir)\n",
        "    dest_dir = Path(dest_dir)\n",
        "    dest_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    moved = 0\n",
        "    for file in source_dir.iterdir():\n",
        "        if file.suffix.lower() in image_extensions:\n",
        "            shutil.move(str(file), dest_dir / file.name)\n",
        "            moved += 1\n",
        "    print(f\"✅ Moved {moved} images → {dest_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6efb6dea",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Unzipped: /Users/mitchellpalmer/Projects/solafune-canopy-capstone-clean/data/raw/zips/train_images.zip → /Users/mitchellpalmer/Projects/solafune-canopy-capstone-clean/data/temp_images\n",
            "✅ Unzipped: /Users/mitchellpalmer/Projects/solafune-canopy-capstone-clean/data/raw/zips/evaluation_images.zip → /Users/mitchellpalmer/Projects/solafune-canopy-capstone-clean/data/processed/images/predict\n"
          ]
        }
      ],
      "source": [
        "# Designate file paths and folders\n",
        "\n",
        "# Ground Truth (gt) Data\n",
        "gt_zip = REPO_ROOT/'data/raw/zips/train_images.zip'\n",
        "gt_folder_path = REPO_ROOT/ 'data/temp_images'\n",
        "\n",
        "# Unlabeled Prediction Data\n",
        "unlabeled_pred_zip = REPO_ROOT / 'data/raw/zips/evaluation_images.zip'\n",
        "unlabeled_pred_path = REPO_ROOT / 'data/processed/images/predict'\n",
        "\n",
        "# Unzip data and extract\n",
        "\n",
        "# Ground Truth (gt) Data\n",
        "unzip_to_folder(gt_zip, gt_folder_path)\n",
        "\n",
        "# Unlabeled Prediction Data\n",
        "unzip_to_folder(unlabeled_pred_zip, unlabeled_pred_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I1sXKcRMs4sY",
      "metadata": {
        "id": "I1sXKcRMs4sY"
      },
      "source": [
        "## Data Split | Train / Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c67a9f0a",
      "metadata": {
        "id": "c67a9f0a"
      },
      "source": [
        "- Automatic dataset split with Python. Using transferable code for designated directory paths\n",
        "\n",
        "- Training Data split 70:30 between **Training** and **Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "341a23b1",
      "metadata": {
        "id": "341a23b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Begin Data Split\n",
            "Completed Data Split       Train - 70%       Val - 15%      Test - 15%\n"
          ]
        }
      ],
      "source": [
        "import os, random, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"Begin Data Split\")\n",
        "# Paths\n",
        "IMG_DIR = Path(REPO_ROOT / \"data/temp_images\")\n",
        "LBL_DIR = Path(REPO_ROOT / \"data/temp_jsons/labels/train_annotations_coco\") #-- Check LBL_DIR path for accuracy. Errors May Occur \n",
        "\n",
        "OUT_DIR = Path(REPO_ROOT/\"data/processed\")\n",
        "splits = {\"train\": 0.7, \"val\": 0.15, \"test\": 0.15}  # 70/15/15 split\n",
        "\n",
        "# Collect all images\n",
        "images = list(IMG_DIR.glob(\"*.jpg\")) + list(IMG_DIR.glob(\"*.png\")) + list(IMG_DIR.glob(\"*.tif\")) # glob is from package Path\n",
        "random.shuffle(images)\n",
        "\n",
        "# Split indices\n",
        "n = len(images)\n",
        "train_end = int(splits[\"train\"] * n)\n",
        "val_end = train_end + int(splits[\"val\"] * n)\n",
        "\n",
        "datasets = {\n",
        "    \"train\": images[:train_end],\n",
        "    \"val\": images[train_end:val_end],\n",
        "    \"test\": images[val_end:],\n",
        "}\n",
        "\n",
        "# Copy files into YOLO structure\n",
        "for split, files in datasets.items():\n",
        "    (OUT_DIR / \"images\" / split).mkdir(parents=True, exist_ok=True)\n",
        "    (OUT_DIR / \"labels\" / split).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for img in files:\n",
        "        label = LBL_DIR / (img.stem + \".txt\")\n",
        "        shutil.copy(img, OUT_DIR / \"images\" / split / img.name)\n",
        "        if label.exists():\n",
        "            shutil.copy(label, OUT_DIR / \"labels\" / split / label.name)\n",
        "\n",
        "\n",
        "try:\n",
        "    test_label_path = Path('data/processed/labels/test')\n",
        "    \n",
        "    # Check if any .txt files exist in the directory\n",
        "    if any(test_label_path.glob('*.txt')):\n",
        "        print('Successful Data Split:\\n  Train - 70%\\n  Val - 15%\\n  Test - 15%')\n",
        "    else:\n",
        "        raise FileNotFoundError('No .txt label files found in test directory.')\n",
        "\n",
        "except Exception as e:\n",
        "    print(f'Data Split Failed - {e}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "MLenv3.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
